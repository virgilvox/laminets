{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laminet Prototype\n",
    "\n",
    "This notebook implements a minimal working prototype for a Laminet model - a neural architecture that models sequential information as a continuous semantic field rather than discrete tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Semantic Field\n",
    "\n",
    "We'll first implement the core field components: field points and the semantic field itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldPoint(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # Position vector in semantic space\n",
    "        self.position = nn.Parameter(torch.randn(embed_dim))\n",
    "        # Velocity vector for field evolution\n",
    "        self.velocity = nn.Parameter(torch.zeros(embed_dim))\n",
    "        # Mass affects how much the point is influenced by forces\n",
    "        self.mass = nn.Parameter(torch.ones(1))\n",
    "        # Semantic charge determines attraction/repulsion properties\n",
    "        self.charge = nn.Parameter(torch.randn(1))\n",
    "        # Decay rate for velocity (damping)\n",
    "        self.decay_rate = nn.Parameter(torch.tensor([0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticField(nn.Module):\n",
    "    def __init__(self, num_points, embed_dim):\n",
    "        super().__init__()\n",
    "        # Create a collection of field points\n",
    "        self.points = nn.ModuleList([FieldPoint(embed_dim) for _ in range(num_points)])\n",
    "        self.embed_dim = embed_dim\n",
    "        # Learnable parameters for force scaling\n",
    "        self.attraction_scale = nn.Parameter(torch.tensor([1.0]))\n",
    "        self.repulsion_scale = nn.Parameter(torch.tensor([0.5]))\n",
    "        \n",
    "        # Store field evolution history for visualization\n",
    "        self.evolution_history = []\n",
    "    \n",
    "    def embed_from_input(self, embeddings):\n",
    "        \"\"\"Initialize field points from input embeddings\"\"\"\n",
    "        for i, point in enumerate(self.points):\n",
    "            if i < len(embeddings):\n",
    "                point.position.data = embeddings[i]\n",
    "        # Reset evolution history\n",
    "        self.evolution_history = [self.get_current_state()]\n",
    "    \n",
    "    def get_current_state(self):\n",
    "        \"\"\"Get current positions and charges of all points\"\"\"\n",
    "        positions = torch.stack([p.position.detach() for p in self.points])\n",
    "        charges = torch.stack([p.charge.detach() for p in self.points])\n",
    "        return {\n",
    "            'positions': positions,\n",
    "            'charges': charges\n",
    "        }\n",
    "    \n",
    "    def semantic_attraction(self, point_i, point_j):\n",
    "        \"\"\"Calculate semantic attraction force between two field points\"\"\"\n",
    "        direction = point_j.position - point_i.position\n",
    "        distance = direction.norm(p=2) + 1e-6  # Avoid division by zero\n",
    "        \n",
    "        # Attraction force based on semantic similarity\n",
    "        force_magnitude = (point_i.charge * point_j.charge) / (distance**2)\n",
    "        attraction = self.attraction_scale * force_magnitude * direction / distance\n",
    "        \n",
    "        # Add repulsion for very close points (prevent collapse)\n",
    "        repulsion_magnitude = self.repulsion_scale / (distance**3 + 1e-6)\n",
    "        repulsion = -repulsion_magnitude * direction / distance\n",
    "        \n",
    "        return attraction + repulsion\n",
    "    \n",
    "    def compute_net_force(self, point_idx):\n",
    "        \"\"\"Calculate net force for a specific field point\"\"\"\n",
    "        forces = []\n",
    "        for j, other_point in enumerate(self.points):\n",
    "            if j == point_idx:\n",
    "                continue\n",
    "            forces.append(self.semantic_attraction(self.points[point_idx], other_point))\n",
    "        \n",
    "        if forces:\n",
    "            return torch.sum(torch.stack(forces), dim=0)\n",
    "        return torch.zeros_like(self.points[point_idx].position)\n",
    "    \n",
    "    def evolve(self, dt=0.01):\n",
    "        \"\"\"Evolve field points based on forces for a single timestep\"\"\"\n",
    "        for idx, point in enumerate(self.points):\n",
    "            # Calculate net force\n",
    "            net_force = self.compute_net_force(idx)\n",
    "            \n",
    "            # Update velocity (F = ma -> a = F/m)\n",
    "            point.velocity = point.velocity + (net_force / point.mass.abs().clamp(min=0.1)) * dt\n",
    "            \n",
    "            # Update position\n",
    "            point.position = point.position + point.velocity * dt\n",
    "            \n",
    "            # Apply velocity decay (damping)\n",
    "            point.velocity *= (1.0 - point.decay_rate.abs().clamp(max=0.2) * dt)\n",
    "        \n",
    "        # Store current state in history\n",
    "        self.evolution_history.append(self.get_current_state())\n",
    "    \n",
    "    def measure_potential_energy(self):\n",
    "        \"\"\"Calculate potential energy of the field (kinetic energy of points)\"\"\"\n",
    "        energy = 0.0\n",
    "        for point in self.points:\n",
    "            # Kinetic energy: 0.5 * m * v^2\n",
    "            energy += 0.5 * point.mass.abs() * (point.velocity.norm(p=2) ** 2)\n",
    "        return energy\n",
    "    \n",
    "    def get_field_encoding(self):\n",
    "        \"\"\"Get field encoding as mean of all point positions\"\"\"\n",
    "        positions = torch.stack([p.position for p in self.points])\n",
    "        return positions.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation of the Laminet Model\n",
    "\n",
    "Now we'll implement the full Laminet model which wraps around the semantic field and provides end-to-end functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laminet(nn.Module):\n",
    "    def __init__(self, input_dim=32, embed_dim=64, output_dim=32, num_field_points=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define model components\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Field initialization module (maps input to initial field)\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Linear(input_dim, embed_dim * 2),\n",
    "            nn.LayerNorm(embed_dim * 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(embed_dim * 2, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # Field evolution module\n",
    "        self.field = SemanticField(num_points=num_field_points, embed_dim=embed_dim)\n",
    "        \n",
    "        # Field decoding module (maps evolved field to output)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 2),\n",
    "            nn.LayerNorm(embed_dim * 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(embed_dim * 2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, time_steps=20, dt=0.01):\n",
    "        \"\"\"Forward pass through Laminet model\"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Process inputs in batch\n",
    "        outputs = []\n",
    "        energies = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Initialize field from input\n",
    "            input_sample = x[i]\n",
    "            \n",
    "            # Reshape input to initialize multiple field points if needed\n",
    "            if len(input_sample.shape) == 1 and self.field.points:\n",
    "                # Split vector into chunks for each field point\n",
    "                chunk_size = input_sample.shape[0] // len(self.field.points)\n",
    "                if chunk_size > 0:\n",
    "                    chunks = input_sample.split(chunk_size)\n",
    "                    embeddings = [self.embedder(chunk) for chunk in chunks[:len(self.field.points)]]\n",
    "                else:\n",
    "                    # If input is too small to split, duplicate it\n",
    "                    embeddings = [self.embedder(input_sample) for _ in range(len(self.field.points))]\n",
    "            else:\n",
    "                # Single embedding for single field point\n",
    "                embeddings = [self.embedder(input_sample)]\n",
    "            \n",
    "            # Initialize field with embeddings\n",
    "            self.field.embed_from_input(embeddings)\n",
    "            \n",
    "            # Evolve field over time\n",
    "            for _ in range(time_steps):\n",
    "                self.field.evolve(dt)\n",
    "            \n",
    "            # Get field encoding and decode output\n",
    "            field_encoding = self.field.get_field_encoding()\n",
    "            output = self.decoder(field_encoding)\n",
    "            \n",
    "            # Store results\n",
    "            outputs.append(output)\n",
    "            energies.append(self.field.measure_potential_energy())\n",
    "        \n",
    "        # Stack results into batch\n",
    "        outputs = torch.stack(outputs)\n",
    "        energies = torch.stack(energies)\n",
    "        \n",
    "        return outputs, energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating a Synthetic Dataset\n",
    "\n",
    "Let's create a simple synthetic dataset for our semantic evolution task (e.g., evolving a concept like \"cold\" to \"warmth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dataset(num_samples=1000, input_dim=32, output_dim=32, num_concepts=3):\n",
    "    \"\"\"Generate a synthetic dataset for concept evolution\"\"\"\n",
    "    # Create synthetic concept vectors\n",
    "    np.random.seed(42)\n",
    "    concepts = {}\n",
    "    \n",
    "    # Generate random concept names for our toy dataset\n",
    "    concept_names = [\n",
    "        \"cold\", \"cool\", \"neutral\", \"warm\", \"hot\",\n",
    "        \"sad\", \"melancholy\", \"neutral\", \"content\", \"happy\",\n",
    "        \"simple\", \"basic\", \"moderate\", \"complex\", \"intricate\"\n",
    "    ]\n",
    "    \n",
    "    # Create random concept embeddings\n",
    "    for name in concept_names:\n",
    "        vec = np.random.randn(input_dim)\n",
    "        vec = vec / np.linalg.norm(vec)  # Normalize\n",
    "        concepts[name] = vec\n",
    "    \n",
    "    # Create concept sequences (paths through concept space)\n",
    "    sequences = [\n",
    "        [\"cold\", \"cool\", \"neutral\", \"warm\", \"hot\"],\n",
    "        [\"sad\", \"melancholy\", \"neutral\", \"content\", \"happy\"],\n",
    "        [\"simple\", \"basic\", \"moderate\", \"complex\", \"intricate\"]\n",
    "    ]\n",
    "    \n",
    "    # Generate samples\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Choose a random sequence\n",
    "        seq_idx = np.random.randint(0, len(sequences))\n",
    "        sequence = sequences[seq_idx]\n",
    "        \n",
    "        # Choose a random starting position in the sequence\n",
    "        start_idx = np.random.randint(0, len(sequence) - 1)\n",
    "        \n",
    "        # Get input and target concepts\n",
    "        input_concept = sequence[start_idx]\n",
    "        target_concept = sequence[start_idx + 1]\n",
    "        \n",
    "        # Add some noise to make the task more challenging\n",
    "        input_vec = concepts[input_concept] + np.random.randn(input_dim) * 0.1\n",
    "        target_vec = concepts[target_concept] + np.random.randn(output_dim) * 0.1\n",
    "        \n",
    "        X.append(input_vec)\n",
    "        y.append(target_vec)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(y), dtype=torch.float32)\n",
    "    \n",
    "    # Create a concept dictionary for evaluation\n",
    "    concept_tensors = {name: torch.tensor(vec, dtype=torch.float32) for name, vec in concepts.items()}\n",
    "    \n",
    "    return X, y, concept_tensors, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_laminet(model, X_train, y_train, num_epochs=100, batch_size=16, lr=0.001):\n",
    "    \"\"\"Train Laminet model\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Track losses\n",
    "    losses = []\n",
    "    energy_values = []\n",
    "    \n",
    "    # Create data loader\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_energy = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs, energy = model(batch_X)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Add regularization based on field energy (optional)\n",
    "            energy_loss = 0.01 * energy.mean()\n",
    "            total_loss = loss + energy_loss\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_energy += energy.mean().item()\n",
    "        \n",
    "        # Record epoch metrics\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        avg_energy = epoch_energy / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        energy_values.append(avg_energy)\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}, Energy: {avg_energy:.6f}\")\n",
    "    \n",
    "    return losses, energy_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(losses, energies):\n",
    "    \"\"\"Plot training metrics\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(energies)\n",
    "    plt.title('Field Energy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Energy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_field_evolution(field_history):\n",
    "    \"\"\"Create PCA visualization of field evolution\"\"\"\n",
    "    # Extract positions from history\n",
    "    all_positions = torch.cat([state['positions'] for state in field_history])\n",
    "    \n",
    "    # Apply PCA to reduce to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    positions_np = all_positions.numpy()\n",
    "    pca_result = pca.fit_transform(positions_np)\n",
    "    \n",
    "    # Reshape back to timesteps and points\n",
    "    num_timesteps = len(field_history)\n",
    "    num_points = field_history[0]['positions'].shape[0]\n",
    "    pca_result = pca_result.reshape(num_timesteps, num_points, 2)\n",
    "    \n",
    "    # Extract charges\n",
    "    charges = [state['charges'].numpy() for state in field_history]\n",
    "    \n",
    "    # Create animation\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        # Plot field points\n",
    "        scatter = ax.scatter(pca_result[frame, :, 0], pca_result[frame, :, 1], \n",
    "                  c=charges[frame].flatten(), cmap='coolwarm', \n",
    "                  s=100, alpha=0.7, vmin=-1, vmax=1)\n",
    "        \n",
    "        # Add trajectories (last 5 steps)\n",
    "        start_idx = max(0, frame - 5)\n",
    "        for i in range(num_points):\n",
    "            traj_x = pca_result[start_idx:frame+1, i, 0]\n",
    "            traj_y = pca_result[start_idx:frame+1, i, 1]\n",
    "            ax.plot(traj_x, traj_y, 'k-', alpha=0.3)\n",
    "        \n",
    "        # Add some styling\n",
    "        ax.set_xlim(pca_result[:, :, 0].min() - 0.5, pca_result[:, :, 0].max() + 0.5)\n",
    "        ax.set_ylim(pca_result[:, :, 1].min() - 0.5, pca_result[:, :, 1].max() + 0.5)\n",
    "        ax.set_title(f'Field Evolution - Step {frame+1}/{num_timesteps}')\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        return scatter,\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update, frames=num_timesteps, interval=100, blit=True)\n",
    "    plt.close()  # Prevent double display in Jupyter\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_concept(embedding, concept_dict):\n",
    "    \"\"\"Find the nearest concept to a given embedding\"\"\"\n",
    "    min_dist = float('inf')\n",
    "    nearest = None\n",
    "    \n",
    "    for name, vec in concept_dict.items():\n",
    "        dist = torch.norm(embedding - vec, p=2)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            nearest = name\n",
    "    \n",
    "    return nearest, min_dist.item()\n",
    "\n",
    "def evaluate_concept_transitions(model, concept_dict, sequences):\n",
    "    \"\"\"Evaluate how well the model transitions between concepts\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        seq_results = []\n",
    "        \n",
    "        for i in range(len(sequence) - 1):\n",
    "            start_concept = sequence[i]\n",
    "            expected_next = sequence[i + 1]\n",
    "            \n",
    "            # Get embedding for start concept\n",
    "            input_embed = concept_dict[start_concept].unsqueeze(0)\n",
    "            \n",
    "            # Evolve through model\n",
    "            with torch.no_grad():\n",
    "                output, _ = model(input_embed)\n",
    "            \n",
    "            # Find nearest concept\n",
    "            predicted_concept, distance = find_nearest_concept(output[0], concept_dict)\n",
    "            \n",
    "            seq_results.append({\n",
    "                'input': start_concept,\n",
    "                'expected': expected_next,\n",
    "                'predicted': predicted_concept,\n",
    "                'distance': distance\n",
    "            })\n",
    "        \n",
    "        results.append(seq_results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic dataset\n",
    "input_dim = 32\n",
    "output_dim = 32\n",
    "embed_dim = 64\n",
    "num_field_points = 5\n",
    "\n",
    "X, y, concept_dict, sequences = generate_synthetic_dataset(\n",
    "    num_samples=1000, \n",
    "    input_dim=input_dim, \n",
    "    output_dim=output_dim\n",
    ")\n",
    "\n",
    "# Split train/test\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Dataset created with {len(X_train)} training and {len(X_test)} test samples\")\n",
    "\n",
    "# Create Laminet model\n",
    "model = Laminet(\n",
    "    input_dim=input_dim,\n",
    "    embed_dim=embed_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_field_points=num_field_points\n",
    ")\n",
    "\n",
    "# Print model parameter count\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model created with {param_count} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "losses, energies = train_laminet(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    num_epochs=100,\n",
    "    batch_size=16,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(losses, energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizing Field Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an example input to visualize field evolution\n",
    "sample_idx = 0\n",
    "sample_input = X_test[sample_idx].unsqueeze(0)\n",
    "\n",
    "# Forward pass to get field evolution\n",
    "with torch.no_grad():\n",
    "    outputs, _ = model(sample_input)\n",
    "\n",
    "# Visualize the field evolution\n",
    "animation = visualize_field_evolution(model.field.evolution_history)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluating Concept Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate concept transitions\n",
    "transition_results = evaluate_concept_transitions(model, concept_dict, sequences)\n",
    "\n",
    "# Display results\n",
    "for i, sequence_results in enumerate(transition_results):\n",
    "    print(f\"Sequence {i+1}: {' -> '.join(sequences[i])}\")\n",
    "    correct = 0\n",
    "    \n",
    "    for result in sequence_results:\n",
    "        match = result['expected'] == result['predicted']\n",
    "        correct += int(match)\n",
    "        print(f\"  {result['input']} -> {result['predicted']} (expected: {result['expected']}) {'✓' if match else '✗'}\")\n",
    "    \n",
    "    accuracy = correct / len(sequence_results) * 100\n",
    "    print(f\"  Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Testing End-to-End Concept Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_concept_chain(model, start_concept, num_steps=5):\n",
    "    \"\"\"Evolve a concept through multiple steps\"\"\"\n",
    "    current_embedding = concept_dict[start_concept].unsqueeze(0)\n",
    "    evolution = [start_concept]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Evolve through model\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(current_embedding)\n",
    "        \n",
    "        # Find nearest concept\n",
    "        predicted_concept, _ = find_nearest_concept(output[0], concept_dict)\n",
    "        evolution.append(predicted_concept)\n",
    "        \n",
    "        # Use output as next input\n",
    "        current_embedding = output\n",
    "    \n",
    "    return evolution\n",
    "\n",
    "# Test chaining multiple evolutions\n",
    "for sequence in sequences:\n",
    "    start_concept = sequence[0]\n",
    "    evolution = evolve_concept_chain(model, start_concept, num_steps=5)\n",
    "    print(f\"Starting with '{start_concept}' evolved to: {' -> '.join(evolution)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "We've successfully implemented a minimal working Laminet model that:\n",
    "\n",
    "1. Represents sequential information as a continuous semantic field\n",
    "2. Evolves the field using simulated forces and dynamics\n",
    "3. Can transform inputs through semantic space along meaningful trajectories\n",
    "4. Visualizes the evolution of semantic fields over time\n",
    "\n",
    "This prototype demonstrates the core concepts behind field evolution models as an alternative to discrete token-based approaches. The next steps would be to:\n",
    "\n",
    "1. Scale up to handle more complex inputs\n",
    "2. Implement more sophisticated field dynamics\n",
    "3. Test on real-world language understanding tasks\n",
    "4. Compare performance with traditional transformer models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}