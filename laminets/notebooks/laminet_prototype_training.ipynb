{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23f6e4f",
   "metadata": {},
   "source": [
    "# Laminet Prototype: Real Training with Coherence Loss (Curated 10k Dataset + Field Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8685a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch matplotlib numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.animation as animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ef661",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/laminet_10k_curated.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "themes = sorted(list(set([item['label'] for item in data])))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(themes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e51986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldPoint(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.position = nn.Parameter(torch.randn(embed_dim))\n",
    "        self.velocity = nn.Parameter(torch.zeros(embed_dim))\n",
    "        self.mass = nn.Parameter(torch.ones(1))\n",
    "        self.charge = nn.Parameter(torch.randn(1))\n",
    "        self.decay_rate = nn.Parameter(torch.abs(torch.randn(1)))\n",
    "\n",
    "class LaminaField(nn.Module):\n",
    "    def __init__(self, embeddings):\n",
    "        super().__init__()\n",
    "        self.points = nn.ModuleList([FieldPoint(embeddings.shape[1]) for _ in range(len(embeddings))])\n",
    "        self.embed_points(embeddings)\n",
    "\n",
    "    def embed_points(self, embeddings):\n",
    "        for point, embed in zip(self.points, embeddings):\n",
    "            point.position.data = embed\n",
    "\n",
    "    def evolve(self, dt=0.01, steps=50, record_positions=False):\n",
    "        trajectory = []\n",
    "        for _ in range(steps):\n",
    "            if record_positions:\n",
    "                current_positions = torch.stack([p.position for p in self.points]).detach().cpu().numpy()\n",
    "                trajectory.append(current_positions)\n",
    "            for idx, point in enumerate(self.points):\n",
    "                net_force = self.compute_net_force(idx)\n",
    "                point.velocity.data = point.velocity.data + net_force * dt\n",
    "                point.position.data = point.position.data + point.velocity.data * dt\n",
    "                point.velocity.data *= (1.0 - point.decay_rate.abs() * dt)\n",
    "        if record_positions:\n",
    "            return trajectory\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def compute_net_force(self, idx):\n",
    "        net_force = 0\n",
    "        point = self.points[idx]\n",
    "        for j, other in enumerate(self.points):\n",
    "            if j == idx:\n",
    "                continue\n",
    "            direction = other.position - point.position\n",
    "            distance = direction.norm(p=2) + 1e-6\n",
    "            force_mag = (point.charge * other.charge) / (distance**2)\n",
    "            net_force += (force_mag * direction / distance)\n",
    "        return net_force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaminetMicro(nn.Module):\n",
    "    def __init__(self, embed_dim=64, output_dim=6):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(128, embed_dim)\n",
    "        self.decoder = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, evolution_steps=50, record_positions=False):\n",
    "        x_embed = self.embedding(x)\n",
    "        field = LaminaField(x_embed)\n",
    "        trajectory = field.evolve(steps=evolution_steps, record_positions=record_positions)\n",
    "        final_pos = torch.stack([p.position for p in field.points], dim=0)\n",
    "        output = self.decoder(final_pos.mean(dim=0))\n",
    "        return output, final_pos, trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_loss(positions, labels):\n",
    "    loss = 0\n",
    "    count = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(i+1, len(labels)):\n",
    "            same = (labels[i] == labels[j])\n",
    "            dist = (positions[i] - positions[j]).norm()\n",
    "            if same:\n",
    "                loss += dist  # Want same-label points to be closer\n",
    "            else:\n",
    "                loss += (1.0 / (dist + 1e-6))  # Want different-label points to repel\n",
    "            count += 1\n",
    "    return loss / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LaminetMicro(output_dim=len(themes)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def generate_batch(batch_size=32):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    inputs = torch.randn(batch_size, 128)\n",
    "    labels = torch.tensor([label_to_idx[item['label']] for item in batch])\n",
    "    return inputs.to(device), labels.to(device)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for _ in tqdm(range(len(data) // batch_size)):\n",
    "        inputs, labels = generate_batch(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output, positions, _ = model(inputs, evolution_steps=30)\n",
    "        loss = coherence_loss(positions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / (len(data) // batch_size)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b70101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_field(trajectory, labels, label_to_color):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    scat = ax.scatter([], [], c=[])\n",
    "\n",
    "    def init():\n",
    "        ax.set_xlim(-5,5)\n",
    "        ax.set_ylim(-5,5)\n",
    "        return scat,\n",
    "\n",
    "    def update(frame):\n",
    "        positions = trajectory[frame]\n",
    "        if positions.shape[1] > 2:\n",
    "            positions = positions[:, :2]\n",
    "        colors = [label_to_color[lbl] for lbl in labels]\n",
    "        scat.set_offsets(positions)\n",
    "        scat.set_color(colors)\n",
    "        return scat,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(trajectory), init_func=init, blit=True)\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "# Visualize after training\n",
    "batch = random.sample(data, 32)\n",
    "inputs = torch.randn(32, 128).to(device)\n",
    "batch_labels = [item['label'] for item in batch]\n",
    "theme_colors = {\n",
    "    'Discovery': 'green',\n",
    "    'Love Story': 'pink',\n",
    "    'Mystery': 'purple',\n",
    "    'Quest': 'blue',\n",
    "    'Revenge': 'red',\n",
    "    'Science': 'orange'\n",
    "}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, _, trajectory = model(inputs, evolution_steps=50, record_positions=True)\n",
    "animate_field(trajectory, batch_labels, theme_colors)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
