{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Laminet Training with Field-Based Text Generation\n",
        "\n",
        "This notebook implements the Laminet (Lamina Networks) architecture with a field-based text generation component. Unlike the previous version which only retrieved responses, this model generates new text using field evolution principles without relying on transformer-based language models.\n",
        "\n",
        "## Setup and Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Install required dependencies\n",
        "!pip install -q torch torchvision matplotlib numpy tqdm scikit-learn ipywidgets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "from transformers import AutoTokenizer, AutoModel, BertTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML, display\n",
        "from sklearn.manifold import TSNE\n",
        "import random\n",
        "import math\n",
        "from torch.cuda.amp import autocast, GradScaler  # For mixed precision training\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
        "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Laminet Base Architecture\n",
        "\n",
        "First, we'll implement the core Laminet components that evolve field points under semantic forces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FieldPoint(nn.Module):\n",
        "    \"\"\"Represents a point in the semantic field with position, velocity, mass, and charge.\"\"\"\n",
        "    def __init__(self, embed_dim, init_position=None, init_mass=1.0, init_charge=0.0, init_decay=0.1):\n",
        "        super().__init__()\n",
        "        # Initialize position or use provided position\n",
        "        if init_position is not None:\n",
        "            self.position = nn.Parameter(init_position.clone().detach())\n",
        "        else:\n",
        "            self.position = nn.Parameter(torch.randn(embed_dim) * 0.02)\n",
        "            \n",
        "        # Initialize velocity with zeros\n",
        "        self.velocity = nn.Parameter(torch.zeros(embed_dim))\n",
        "        \n",
        "        # Mass and charge parameters\n",
        "        self.log_mass = nn.Parameter(torch.tensor(math.log(init_mass)))\n",
        "        self.charge = nn.Parameter(torch.tensor(init_charge))\n",
        "        self.decay = nn.Parameter(torch.tensor(init_decay))\n",
        "        \n",
        "    @property\n",
        "    def mass(self):\n",
        "        # Mass is always positive\n",
        "        return torch.exp(self.log_mass)\n",
        "    \n",
        "    def reset_velocity(self):\n",
        "        # Reset velocity to zero (useful between batches)\n",
        "        with torch.no_grad():\n",
        "            self.velocity.zero_()\n",
        "            \n",
        "    def __repr__(self):\n",
        "        return f\"FieldPoint(pos={self.position.norm():.2f}, vel={self.velocity.norm():.2f}, mass={self.mass.item():.2f}, charge={self.charge.item():.2f})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class EvolutionEngine(nn.Module):\n",
        "    \"\"\"Evolves field points based on semantic forces.\"\"\"\n",
        "    def __init__(self, epsilon=1e-6, min_distance=0.1, max_force=10.0):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon  # Prevent division by zero\n",
        "        self.min_distance = min_distance  # Minimum distance to prevent excessive forces\n",
        "        self.max_force = max_force  # Maximum force magnitude\n",
        "        \n",
        "    def compute_forces(self, positions, charges, masses):\n",
        "        \"\"\"Optimized force computation with batch operations.\"\"\"\n",
        "        n_points = positions.shape[0]\n",
        "        \n",
        "        # Vectorized operations for pairwise calculations\n",
        "        # Compute all distances at once\n",
        "        diffs = positions.unsqueeze(0) - positions.unsqueeze(1)  # [n, n, dim]\n",
        "        squared_dists = torch.sum(diffs**2, dim=-1)  # [n, n]\n",
        "        squared_dists = torch.clamp(squared_dists, min=self.min_distance**2) + self.epsilon\n",
        "        \n",
        "        # Compute charge products efficiently\n",
        "        charge_prods = charges.unsqueeze(0) * charges.unsqueeze(1)  # [n, n]\n",
        "        \n",
        "        # Compute force magnitudes\n",
        "        force_mags = charge_prods / squared_dists  # [n, n]\n",
        "        force_mags = torch.clamp(force_mags, min=-self.max_force, max=self.max_force)\n",
        "        \n",
        "        # Mask out self-interactions\n",
        "        mask = 1.0 - torch.eye(n_points, device=positions.device)\n",
        "        force_mags = force_mags * mask\n",
        "        \n",
        "        # Normalize directions and compute forces\n",
        "        dist = torch.sqrt(squared_dists).unsqueeze(-1)  # [n, n, 1]\n",
        "        norm_diffs = diffs / (dist + self.epsilon)  # [n, n, dim]\n",
        "        \n",
        "        # Apply forces\n",
        "        forces = torch.sum(norm_diffs * force_mags.unsqueeze(-1), dim=1)  # [n, dim]\n",
        "        \n",
        "        return forces\n",
        "        \n",
        "    def forward(self, field_points, delta_t=0.1, steps=5):\n",
        "        \"\"\"Evolve field points over time.\"\"\"\n",
        "        # Extract field point properties\n",
        "        positions = torch.stack([p.position for p in field_points])\n",
        "        velocities = torch.stack([p.velocity for p in field_points])\n",
        "        masses = torch.stack([p.mass for p in field_points])\n",
        "        charges = torch.stack([p.charge for p in field_points])\n",
        "        decays = torch.stack([p.decay for p in field_points])\n",
        "        \n",
        "        # Store evolution history for visualization\n",
        "        position_history = [positions.clone().detach()]\n",
        "        \n",
        "        # Evolve the field for multiple steps\n",
        "        for step in range(steps):\n",
        "            # Compute forces\n",
        "            forces = self.compute_forces(positions, charges, masses)\n",
        "            \n",
        "            # Update velocities (F = ma -> a = F/m)\n",
        "            accelerations = forces / masses.unsqueeze(1)\n",
        "            \n",
        "            # Apply velocity decay (damping)\n",
        "            velocity_decay = (1.0 - decays * delta_t).unsqueeze(1)\n",
        "            velocities = velocity_decay * velocities + accelerations * delta_t\n",
        "            \n",
        "            # Update positions\n",
        "            positions = positions + velocities * delta_t\n",
        "            \n",
        "            # Store position history\n",
        "            position_history.append(positions.clone().detach())\n",
        "        \n",
        "        # Update field points with new positions and velocities\n",
        "        for i, point in enumerate(field_points):\n",
        "            point.position.data = positions[i].data\n",
        "            point.velocity.data = velocities[i].data\n",
        "        \n",
        "        # Calculate potential energy of the system (simplified for speed)\n",
        "        potential_energy = 0.0\n",
        "        n_points = len(field_points)\n",
        "        # Calculate potential energy for a subset of pairs\n",
        "        sample_rate = 0.5  # Only calculate half of all pairs\n",
        "        for i in range(n_points):\n",
        "            for j in range(i+1, n_points):\n",
        "                if random.random() < sample_rate:\n",
        "                    dist = torch.norm(field_points[i].position - field_points[j].position)\n",
        "                    potential_energy += (field_points[i].charge * field_points[j].charge) / (dist + self.epsilon)\n",
        "        potential_energy = potential_energy / sample_rate  # Scale to account for sampling\n",
        "        \n",
        "        return position_history, potential_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Field-Based Text Generator\n",
        "\n",
        "Now we'll implement a text generator that uses field evolution principles to generate text, avoiding conventional transformer architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FieldBasedGenerator(nn.Module):\n",
        "    \"\"\"Generates text directly from field embeddings using field evolution principles.\"\"\"\n",
        "    def __init__(self, field_dim, vocab_size, max_seq_len=50, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.field_dim = field_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Special tokens\n",
        "        self.pad_token_id = 0\n",
        "        self.bos_token_id = 101  # [CLS] token in BERT\n",
        "        self.eos_token_id = 102  # [SEP] token in BERT\n",
        "        \n",
        "        # Word embeddings representing semantic points in the field\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, field_dim)\n",
        "        \n",
        "        # Field-based sequence generator - create attractor points for the sequence field\n",
        "        self.sequence_field = nn.ModuleList([\n",
        "            FieldPoint(field_dim, init_charge=0.5) \n",
        "            for _ in range(hidden_dim)\n",
        "        ])\n",
        "        \n",
        "        # Sequence evolution engine with smaller min_distance for finer control\n",
        "        self.sequence_engine = EvolutionEngine(epsilon=1e-6, min_distance=0.05, max_force=5.0)\n",
        "        \n",
        "        # Output projection from field to vocabulary\n",
        "        self.output_projection = nn.Sequential(\n",
        "            nn.Linear(field_dim, field_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(field_dim * 2, vocab_size)\n",
        "        )\n",
        "        \n",
        "        # Sequence position encoder\n",
        "        self.position_encoder = nn.Embedding(max_seq_len, field_dim)\n",
        "        \n",
        "    def forward(self, field_embedding, max_length=30, temperature=0.8, top_k=50):\n",
        "        \"\"\"Generate text from a field embedding.\"\"\"\n",
        "        batch_size = field_embedding.size(0)\n",
        "        generated_ids = torch.full((batch_size, 1), self.bos_token_id, dtype=torch.long, device=field_embedding.device)\n",
        "        \n",
        "        # Create initial sequence point from field embedding\n",
        "        sequence_points = []\n",
        "        for b in range(batch_size):\n",
        "            sequence_points.append(\n",
        "                FieldPoint(\n",
        "                    self.field_dim,\n",
        "                    init_position=field_embedding[b],\n",
        "                    init_mass=0.5,\n",
        "                    init_charge=-1.0\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Generate sequence token by token\n",
        "        for i in range(max_length):\n",
        "            new_sequence_points = []\n",
        "            next_token_ids = []\n",
        "            \n",
        "            for b, sequence_point in enumerate(sequence_points):\n",
        "                # Skip if already generated EOS\n",
        "                if generated_ids[b, -1].item() == self.eos_token_id:\n",
        "                    new_sequence_points.append(sequence_point)  # Keep as is\n",
        "                    next_token_ids.append(self.pad_token_id)  # Add padding token\n",
        "                    continue\n",
        "                \n",
        "                # Evolve sequence point with sequence field\n",
        "                all_points = [sequence_point] + list(self.sequence_field)\n",
        "                \n",
        "                # Add position encoding\n",
        "                pos_encoding = self.position_encoder(torch.tensor([i], device=device))[0]\n",
        "                sequence_point.position.data = sequence_point.position.data + 0.1 * pos_encoding\n",
        "                \n",
        "                # Evolve the field\n",
        "                position_history, _ = self.sequence_engine(all_points, steps=3)\n",
        "                \n",
        "                # Get evolved position\n",
        "                evolved_position = position_history[-1][0]\n",
        "                \n",
        "                # Project to vocabulary\n",
        "                logits = self.output_projection(evolved_position)\n",
        "                \n",
        "                # Apply temperature and sample\n",
        "                logits = logits / temperature\n",
        "                \n",
        "                # Apply top-k sampling\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "                probs = F.softmax(top_k_logits, dim=-1)\n",
        "                \n",
        "                # Sample from the top-k distribution\n",
        "                top_k_idx = torch.multinomial(probs, 1).item()\n",
        "                next_token_id = top_k_indices[top_k_idx].item()\n",
        "                next_token_ids.append(next_token_id)\n",
        "                \n",
        "                # Get word embedding for the next token\n",
        "                word_embedding = self.word_embeddings(torch.tensor([next_token_id], device=evolved_position.device))[0]\n",
        "                \n",
        "                # Create new sequence point combining evolved position and word embedding\n",
        "                new_sequence_point = FieldPoint(\n",
        "                    self.field_dim,\n",
        "                    init_position=(evolved_position + word_embedding) / 2,  # Blend the two\n",
        "                    init_mass=0.5,\n",
        "                    init_charge=-1.0\n",
        "                )\n",
        "                \n",
        "                new_sequence_points.append(new_sequence_point)\n",
        "            \n",
        "            # Update sequence points\n",
        "            sequence_points = new_sequence_points\n",
        "            \n",
        "            # Add new tokens to generated_ids\n",
        "            next_token_tensor = torch.tensor(next_token_ids, device=generated_ids.device).unsqueeze(1)\n",
        "            generated_ids = torch.cat([generated_ids, next_token_tensor], dim=1)\n",
        "            \n",
        "            # Check if all sequences have EOS token\n",
        "            if (generated_ids == self.eos_token_id).sum(dim=1).bool().all():\n",
        "                break\n",
        "        \n",
        "        return generated_ids\n",
        "    \n",
        "    def train_step(self, field_embeddings, target_ids, teacher_forcing_ratio=0.5):\n",
        "        \"\"\"Train the generator on target sequences.\"\"\"\n",
        "        batch_size = field_embeddings.size(0)\n",
        "        seq_len = target_ids.size(1)\n",
        "        \n",
        "        # Initialize loss\n",
        "        loss = 0.0\n",
        "        \n",
        "        # Create initial sequence points from field embeddings\n",
        "        sequence_points = []\n",
        "        for b in range(batch_size):\n",
        "            sequence_points.append(\n",
        "                FieldPoint(\n",
        "                    self.field_dim,\n",
        "                    init_position=field_embeddings[b],\n",
        "                    init_mass=0.5,\n",
        "                    init_charge=-1.0\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Loop through sequence\n",
        "        for i in range(1, seq_len):  # Start from 1 to predict after BOS token\n",
        "            new_sequence_points = []\n",
        "            step_loss = 0.0\n",
        "            \n",
        "            for b, sequence_point in enumerate(sequence_points):\n",
        "                # Evolve sequence point with sequence field\n",
        "                all_points = [sequence_point] + list(self.sequence_field)\n",
        "                \n",
        "                # Add position encoding\n",
        "                pos_encoding = self.position_encoder(torch.tensor([i-1], device=device))[0]\n",
        "                sequence_point.position.data = sequence_point.position.data + 0.1 * pos_encoding\n",
        "                \n",
        "                # Evolve the field\n",
        "                position_history, _ = self.sequence_engine(all_points, steps=3)\n",
        "                \n",
        "                # Get evolved position\n",
        "                evolved_position = position_history[-1][0]\n",
        "                \n",
        "                # Project to vocabulary\n",
        "                logits = self.output_projection(evolved_position)\n",
        "                \n",
        "                # Compute loss against target token\n",
        "                target = target_ids[b, i]\n",
        "                token_loss = F.cross_entropy(logits.unsqueeze(0), target.unsqueeze(0))\n",
        "                step_loss += token_loss\n",
        "                \n",
        "                # Get next token (either from target for teacher forcing or from predicted token)\n",
        "                use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "                \n",
        "                if use_teacher_forcing:\n",
        "                    next_token_id = target.item()\n",
        "                else:\n",
        "                    # Sample from predicted distribution\n",
        "                    probs = F.softmax(logits, dim=-1)\n",
        "                    next_token_id = torch.multinomial(probs, 1).item()\n",
        "                \n",
        "                # Get word embedding for the next token\n",
        "                word_embedding = self.word_embeddings(torch.tensor([next_token_id], device=evolved_position.device))[0]\n",
        "                \n",
        "                # Create new sequence point combining evolved position and word embedding\n",
        "                new_sequence_point = FieldPoint(\n",
        "                    self.field_dim,\n",
        "                    init_position=(evolved_position + word_embedding) / 2,\n",
        "                    init_mass=0.5,\n",
        "                    init_charge=-1.0\n",
        "                )\n",
        "                \n",
        "                new_sequence_points.append(new_sequence_point)\n",
        "            \n",
        "            # Update sequence points\n",
        "            sequence_points = new_sequence_points\n",
        "            \n",
        "            # Add step loss to total loss\n",
        "            loss += step_loss / batch_size\n",
        "        \n",
        "        # Return average loss\n",
        "        return loss / (seq_len - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enhanced Laminet Model with Text Generation\n",
        "\n",
        "Now we'll combine the base Laminet model with the field-based text generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class GenerativeLaminet(nn.Module):\n",
        "    \"\"\"Enhanced Laminet model with field-based text generation capabilities.\"\"\"\n",
        "    def __init__(self, \n",
        "                 encoder_model_name='sentence-transformers/all-MiniLM-L6-v2', \n",
        "                 field_dim=64,\n",
        "                 num_attractor_points=20,\n",
        "                 num_evolution_steps=5,\n",
        "                 vocab_size=30522,  # BERT vocab size\n",
        "                 delta_t=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Text tokenizer (BERT tokenizer)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        # Encoder - use a pretrained sentence transformer\n",
        "        self.encoder_tokenizer = AutoTokenizer.from_pretrained(encoder_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(encoder_model_name)\n",
        "        \n",
        "        # Get the encoder output dimension\n",
        "        self.embed_dim = self.encoder.config.hidden_size\n",
        "        \n",
        "        # Project encoder output to field space if dimensions don't match\n",
        "        self.field_dim = field_dim\n",
        "        if self.embed_dim != self.field_dim:\n",
        "            self.projector = nn.Linear(self.embed_dim, self.field_dim)\n",
        "        else:\n",
        "            self.projector = nn.Identity()\n",
        "        \n",
        "        # Memory field - attractor points in the field\n",
        "        self.attractor_points = nn.ModuleList([\n",
        "            FieldPoint(field_dim, init_charge=1.0) \n",
        "            for _ in range(num_attractor_points)\n",
        "        ])\n",
        "        \n",
        "        # Evolution engine\n",
        "        self.evolution_engine = EvolutionEngine()\n",
        "        self.num_evolution_steps = num_evolution_steps\n",
        "        self.delta_t = delta_t\n",
        "        \n",
        "        # Decoder - transforms evolved field back to embedding space\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(field_dim, field_dim*2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(field_dim*2, field_dim),\n",
        "        )\n",
        "        \n",
        "        # Field-based text generator\n",
        "        self.text_generator = FieldBasedGenerator(\n",
        "            field_dim=field_dim,\n",
        "            vocab_size=vocab_size,\n",
        "            max_seq_len=50,\n",
        "            hidden_dim=64\n",
        "        )\n",
        "        \n",
        "        # Store the last field evolution for visualization\n",
        "        self.last_field_history = None\n",
        "        \n",
        "    def encode_text(self, texts):\n",
        "        \"\"\"Encode texts to embeddings.\"\"\"\n",
        "        # Tokenize texts\n",
        "        inputs = self.encoder_tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        # Get embeddings\n",
        "        with torch.no_grad():\n",
        "            outputs = self.encoder(**inputs)\n",
        "            # Use CLS token or mean pooling\n",
        "            embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
        "            # Project to field dimension if needed\n",
        "            field_embeddings = self.projector(embeddings)\n",
        "            \n",
        "        return field_embeddings\n",
        "    \n",
        "    def create_query_point(self, embedding):\n",
        "        \"\"\"Create a query point from input embedding.\"\"\"\n",
        "        return FieldPoint(\n",
        "            self.field_dim,\n",
        "            init_position=embedding,\n",
        "            init_mass=0.5,  # Lower mass to be more influenced by attractors\n",
        "            init_charge=-1.0  # Opposite charge to be attracted to memory points\n",
        "        )\n",
        "    \n",
        "    def evolve_field(self, query_point):\n",
        "        \"\"\"Evolve the field with query and attractor points.\"\"\"\n",
        "        # Combine query and attractor points\n",
        "        all_points = [query_point] + list(self.attractor_points)\n",
        "        \n",
        "        # Evolve field\n",
        "        position_history, potential_energy = self.evolution_engine(\n",
        "            all_points, \n",
        "            delta_t=self.delta_t, \n",
        "            steps=self.num_evolution_steps\n",
        "        )\n",
        "        \n",
        "        # Store history for visualization\n",
        "        self.last_field_history = position_history\n",
        "        \n",
        "        # Return evolved query point position\n",
        "        return query_point.position, potential_energy\n",
        "    \n",
        "    def forward(self, source_texts):\n",
        "        \"\"\"Process input texts through the Laminet model.\"\"\"\n",
        "        # Encode source texts\n",
        "        source_embeddings = self.encode_text(source_texts)\n",
        "        \n",
        "        # Process each source embedding\n",
        "        evolved_embeddings = []\n",
        "        potential_energies = []\n",
        "        \n",
        "        for embedding in source_embeddings:\n",
        "            # Create query point\n",
        "            query_point = self.create_query_point(embedding)\n",
        "            \n",
        "            # Evolve field\n",
        "            evolved_embedding, potential_energy = self.evolve_field(query_point)\n",
        "            \n",
        "            evolved_embeddings.append(evolved_embedding)\n",
        "            potential_energies.append(potential_energy)\n",
        "            \n",
        "        # Stack evolved embeddings\n",
        "        evolved_embeddings = torch.stack(evolved_embeddings)\n",
        "        potential_energies = torch.stack(potential_energies)\n",
        "        \n",
        "        # Decode evolved embeddings\n",
        "        decoded_embeddings = self.decoder(evolved_embeddings)\n",
        "        \n",
        "        return decoded_embeddings, potential_energies\n",
        "    \n",
        "    def generate_text(self, source_texts, max_length=30, temperature=0.8, top_k=50):\n",
        "        \"\"\"Generate text responses using field-based generation.\"\"\"\n",
        "        # Get evolved field embeddings\n",
        "        evolved_embeddings, _ = self.forward(source_texts)\n",
        "        \n",
        "        # Use text generator to produce token IDs\n",
        "        token_ids = self.text_generator(evolved_embeddings, max_length, temperature, top_k)\n",
        "        \n",
        "        # Convert token IDs to text\n",
        "        texts = []\n",
        "        for ids in token_ids:\n",
        "            # Remove padding, BOS, and EOS tokens\n",
        "            text = self.tokenizer.decode(ids, skip_special_tokens=True)\n",
        "            texts.append(text)\n",
        "            \n",
        "        return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "We'll prepare the dataset for training with the text generation component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class LaminetDataset(Dataset):\n",
        "    \"\"\"Dataset for Laminet training with text generation.\"\"\"\n",
        "    def __init__(self, samples_path, tokenizer):\n",
        "        \"\"\"Initialize dataset from samples JSON file.\"\"\"\n",
        "        with open(samples_path, 'r') as f:\n",
        "            self.samples = json.load(f)\n",
        "        self.tokenizer = tokenizer\n",
        "        print(f\"Loaded {len(self.samples)} samples\")\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a sample by index.\"\"\"\n",
        "        sample = self.samples[idx]\n",
        "        \n",
        "        # Tokenize target text for the text generator\n",
        "        target_encoding = self.tokenizer(\n",
        "            sample['target_text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=50,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'sample_id': sample['sample_id'],\n",
        "            'source_text': sample['source_text'],\n",
        "            'target_text': sample['target_text'],\n",
        "            'source_space': sample['source_space'],\n",
        "            'source_concept': sample['source_concept'],\n",
        "            'target_space': sample['target_space'],\n",
        "            'target_concept': sample['target_concept'],\n",
        "            'transition_pattern': sample['transition_pattern'],\n",
        "            'target_input_ids': target_encoding['input_ids'][0],\n",
        "            'target_attention_mask': target_encoding['attention_mask'][0]\n",
        "        }\n",
        "    \n",
        "    def get_spaces_and_concepts(self):\n",
        "        \"\"\"Get unique spaces and concepts for visualization.\"\"\"\n",
        "        spaces = set()\n",
        "        concepts = {}\n",
        "        \n",
        "        for sample in self.samples:\n",
        "            spaces.add(sample['source_space'])\n",
        "            spaces.add(sample['target_space'])\n",
        "            \n",
        "            source_space = sample['source_space']\n",
        "            target_space = sample['target_space']\n",
        "            source_concept = sample['source_concept']\n",
        "            target_concept = sample['target_concept']\n",
        "            \n",
        "            if source_space not in concepts:\n",
        "                concepts[source_space] = set()\n",
        "            if target_space not in concepts:\n",
        "                concepts[target_space] = set()\n",
        "                \n",
        "            concepts[source_space].add(source_concept)\n",
        "            concepts[target_space].add(target_concept)\n",
        "            \n",
        "        return spaces, concepts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize model\n",
        "model = GenerativeLaminet(\n",
        "    encoder_model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "    field_dim=64,\n",
        "    num_attractor_points=20,\n",
        "    num_evolution_steps=5\n",
        ").to(device)\n",
        "\n",
        "# Upload dataset to Colab if needed\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Check if dataset exists\n",
        "dataset_path = '/content/laminet_samples_10k.json'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Please upload the dataset file:\")\n",
        "    uploaded = files.upload()\n",
        "    dataset_path = list(uploaded.keys())[0]\n",
        "    # If it's uploaded to a different path, move it to the expected path\n",
        "    if dataset_path != 'laminet_samples_10k.json':\n",
        "        !mv \"{dataset_path}\" \"/content/laminet_samples_10k.json\"\n",
        "        dataset_path = '/content/laminet_samples_10k.json'\n",
        "    print(f\"Dataset uploaded to {dataset_path}\")\n",
        "else:\n",
        "    print(f\"Dataset already exists at {dataset_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Load the dataset\n",
        "dataset = LaminetDataset(dataset_path, model.tokenizer)\n",
        "\n",
        "# Split into train and validation sets (90/10 split)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders with larger batch size\n",
        "batch_size = 32  # Slightly smaller due to higher memory requirements of generator\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training with Text Generation\n",
        "\n",
        "We'll train the model with both field evolution and text generation objectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define loss functions\n",
        "cosine_loss = nn.CosineEmbeddingLoss()\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "# Define optimizer with learning rate scheduler\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.AdamW(\n",
        "    [{'params': model.parameters(), 'lr': learning_rate}],\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='min', \n",
        "    factor=0.5, \n",
        "    patience=1,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Initialize grad scaler for mixed precision training\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def train_epoch(model, train_loader, optimizer, epoch, scaler):\n",
        "    \"\"\"Train for one epoch with mixed precision.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_field_loss = 0\n",
        "    total_gen_loss = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        # Get source and target texts\n",
        "        source_texts = batch['source_text']\n",
        "        target_texts = batch['target_text']\n",
        "        target_input_ids = batch['target_input_ids'].to(device)\n",
        "        \n",
        "        # Reset optimizer\n",
        "        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
        "        \n",
        "        # Forward pass with mixed precision\n",
        "        with autocast():\n",
        "            # Get evolved embeddings\n",
        "            source_evolved, potential_energy = model(source_texts)\n",
        "            \n",
        "            # Get target embeddings\n",
        "            with torch.no_grad():\n",
        "                target_embeddings = model.encode_text(target_texts)\n",
        "            \n",
        "            # Compute cosine similarity loss for field evolution\n",
        "            target_ones = torch.ones(source_evolved.size(0)).to(device)\n",
        "            field_loss = cosine_loss(source_evolved, target_embeddings, target_ones)\n",
        "            \n",
        "            # Compute field coherence loss (regularization)\n",
        "            coherence_loss = torch.mean(potential_energy)\n",
        "            \n",
        "            # Compute text generation loss\n",
        "            gen_loss = model.text_generator.train_step(source_evolved, target_input_ids)\n",
        "            \n",
        "            # Total loss (weighted sum)\n",
        "            loss = field_loss + 0.1 * coherence_loss + 0.5 * gen_loss\n",
        "        \n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        # Unscale before gradient clipping\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        # Optimizer step with gradient scaling\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        # Update statistics\n",
        "        total_loss += loss.item() * len(source_texts)\n",
        "        total_field_loss += field_loss.item() * len(source_texts)\n",
        "        total_gen_loss += gen_loss.item() * len(source_texts)\n",
        "        total_samples += len(source_texts)\n",
        "        \n",
        "        # Update progress bar\n",
        "        avg_loss = total_loss / total_samples\n",
        "        avg_field_loss = total_field_loss / total_samples\n",
        "        avg_gen_loss = total_gen_loss / total_samples\n",
        "        \n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{avg_loss:.4f}\", \n",
        "            'field_loss': f\"{avg_field_loss:.4f}\", \n",
        "            'gen_loss': f\"{avg_gen_loss:.4f}\"\n",
        "        })\n",
        "        \n",
        "    return total_loss / total_samples, total_field_loss / total_samples, total_gen_loss / total_samples\n",
        "\n",
        "def validate(model, val_loader, epoch):\n",
        "    \"\"\"Validate the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_field_loss = 0\n",
        "    total_gen_loss = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    progress_bar = tqdm(val_loader, desc=f\"Validation {epoch}\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            # Get source and target texts\n",
        "            source_texts = batch['source_text']\n",
        "            target_texts = batch['target_text']\n",
        "            target_input_ids = batch['target_input_ids'].to(device)\n",
        "            \n",
        "            # Get evolved embeddings\n",
        "            source_evolved, potential_energy = model(source_texts)\n",
        "            \n",
        "            # Get target embeddings\n",
        "            target_embeddings = model.encode_text(target_texts)\n",
        "            \n",
        "            # Compute losses\n",
        "            target_ones = torch.ones(source_evolved.size(0)).to(device)\n",
        "            field_loss = cosine_loss(source_evolved, target_embeddings, target_ones)\n",
        "            \n",
        "            # Simple estimate for generation loss (without updating model)\n",
        "            logits = model.text_generator.output_projection(source_evolved)\n",
        "            gen_loss = F.cross_entropy(logits, target_input_ids[:, 1])\n",
        "            \n",
        "            # Total loss\n",
        "            loss = field_loss + 0.5 * gen_loss\n",
        "            \n",
        "            # Update statistics\n",
        "            total_loss += loss.item() * len(source_texts)\n",
        "            total_field_loss += field_loss.item() * len(source_texts)\n",
        "            total_gen_loss += gen_loss.item() * len(source_texts)\n",
        "            total_samples += len(source_texts)\n",
        "            \n",
        "            # Update progress bar\n",
        "            avg_loss = total_loss / total_samples\n",
        "            progress_bar.set_postfix({'val_loss': f\"{avg_loss:.4f}\"})\n",
        "    \n",
        "    return total_loss / total_samples, total_field_loss / total_samples, total_gen_loss / total_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create directory for checkpoints\n",
        "os.makedirs('/content/checkpoints', exist_ok=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 8\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Training history\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "field_losses = []\n",
        "gen_losses = []\n",
        "\n",
        "# Enable cuDNN benchmark for faster training\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Train\n",
        "    train_loss, train_field_loss, train_gen_loss = train_epoch(model, train_loader, optimizer, epoch, scaler)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_field_loss, val_gen_loss = validate(model, val_loader, epoch)\n",
        "    val_losses.append(val_loss)\n",
        "    field_losses.append(val_field_loss)\n",
        "    gen_losses.append(val_gen_loss)\n",
        "    \n",
        "    # Update learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Save checkpoint if validation loss improved\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        checkpoint_path = f\"/content/checkpoints/laminet_generative_epoch_{epoch}_loss_{val_loss:.4f}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Saved checkpoint to {checkpoint_path}\")\n",
        "    \n",
        "    # Report time elapsed\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Time elapsed: {elapsed/60:.2f} minutes\")\n",
        "    \n",
        "# Report total training time\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\nTotal training time: {total_time/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Total Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), field_losses, label='Field Loss')\n",
        "plt.plot(range(1, num_epochs + 1), gen_losses, label='Generation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Component Losses')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/loss_curve_generative.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Save the final model\n",
        "final_model_path = \"/content/laminet_generative_final.pt\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'field_dim': model.field_dim,\n",
        "    'num_attractor_points': len(model.attractor_points),\n",
        "    'num_evolution_steps': model.num_evolution_steps,\n",
        "    'encoder_model_name': 'sentence-transformers/all-MiniLM-L6-v2',\n",
        "}, final_model_path)\n",
        "print(f\"Saved final model to {final_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Text Generation\n",
        "\n",
        "Let's test the model's ability to generate text from semantic fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def test_generation(model, test_texts, temperature=0.8, top_k=50):\n",
        "    \"\"\"Test text generation from input texts.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    print(\"\\nGenerating responses:\")\n",
        "    for text in test_texts:\n",
        "        print(f\"\\nInput: {text}\")\n",
        "        \n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            generated_texts = model.generate_text([text], temperature=temperature, top_k=top_k)\n",
        "            response = generated_texts[0]\n",
        "            \n",
        "        print(f\"Generated: {response}\")\n",
        "        \n",
        "        # For comparison, find closest concept\n",
        "        with torch.no_grad():\n",
        "            input_embedding = model.encode_text([text])[0]\n",
        "            query_point = model.create_query_point(input_embedding)\n",
        "            evolved_embedding, _ = model.evolve_field(query_point)\n",
        "            \n",
        "            # Find closest target text in dataset\n",
        "            closest_texts = []\n",
        "            closest_similarities = []\n",
        "            \n",
        "            # Get sample target texts\n",
        "            sample_texts = [sample['target_text'] for sample in random.sample(dataset.samples, min(100, len(dataset)))]\n",
        "            \n",
        "            # Get embeddings for sample texts\n",
        "            sample_embeddings = model.encode_text(sample_texts)\n",
        "            \n",
        "            # Compute similarities\n",
        "            similarities = F.cosine_similarity(evolved_embedding.unsqueeze(0), sample_embeddings)\n",
        "            \n",
        "            # Get top 3 closest texts\n",
        "            top_indices = similarities.argsort(descending=True)[:3]\n",
        "            for idx in top_indices:\n",
        "                closest_texts.append(sample_texts[idx])\n",
        "                closest_similarities.append(similarities[idx].item())\n",
        "            \n",
        "        # Print closest texts for comparison\n",
        "        print(\"Closest dataset examples:\")\n",
        "        for i, (text, sim) in enumerate(zip(closest_texts, closest_similarities)):\n",
        "            print(f\"{i+1}. (sim: {sim:.4f}) {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Test with some example texts\n",
        "test_texts = [\n",
        "    \"The temperature outside was freezing cold.\",\n",
        "    \"She felt sad looking at the old photographs.\",\n",
        "    \"The problem was extremely complex with many variables.\",\n",
        "    \"The artist's creativity allowed her to see unique solutions.\"\n",
        "]\n",
        "\n",
        "test_generation(model, test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Test with different temperatures\n",
        "print(\"\\nTesting with different temperatures:\")\n",
        "input_text = \"The building was very complex with many intricate details.\"\n",
        "print(f\"\\nInput: {input_text}\")\n",
        "\n",
        "for temp in [0.5, 0.7, 1.0, 1.3]:\n",
        "    with torch.no_grad():\n",
        "        generated_texts = model.generate_text([input_text], temperature=temp, top_k=50)\n",
        "        response = generated_texts[0]\n",
        "    \n",
        "    print(f\"\\nTemperature {temp}: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generative Chatbot Interface\n",
        "\n",
        "Create a chatbot that generates new text responses rather than just retrieving existing ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class GenerativeLaminetChatbot:\n",
        "    \"\"\"Chatbot interface for the GenerativeLaminet model.\"\"\"\n",
        "    def __init__(self, model, memory_size=5):\n",
        "        self.model = model\n",
        "        self.memory_size = memory_size\n",
        "        self.memory = []  # Store recent interactions\n",
        "        self.temperature = 0.8  # Default temperature for generation\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        \"\"\"Process user input and generate a response.\"\"\"\n",
        "        # Add user input to memory\n",
        "        self.memory.append({'role': 'user', 'text': user_input})\n",
        "        \n",
        "        # Generate response using field-based generation\n",
        "        with torch.no_grad():\n",
        "            generated_texts = self.model.generate_text(\n",
        "                [user_input], \n",
        "                temperature=self.temperature, \n",
        "                top_k=50\n",
        "            )\n",
        "            response = generated_texts[0]\n",
        "        \n",
        "        # Add response to memory\n",
        "        self.memory.append({'role': 'assistant', 'text': response})\n",
        "        \n",
        "        # Trim memory if too large\n",
        "        if len(self.memory) > self.memory_size * 2:\n",
        "            self.memory = self.memory[-self.memory_size * 2:]\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    def get_conversation_history(self):\n",
        "        \"\"\"Get the conversation history.\"\"\"\n",
        "        return self.memory\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"Reset the conversation history.\"\"\"\n",
        "        self.memory = []\n",
        "        return \"Conversation history cleared.\"\n",
        "    \n",
        "    def set_temperature(self, temperature):\n",
        "        \"\"\"Set the temperature for text generation.\"\"\"\n",
        "        self.temperature = temperature\n",
        "        return f\"Temperature set to {temperature}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize chatbot\n",
        "chatbot = GenerativeLaminetChatbot(model)\n",
        "\n",
        "# Interactive chat interface using IPython widgets\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Chat history display\n",
        "chat_history = widgets.HTML(value=\"\")\n",
        "\n",
        "# Text input for user\n",
        "text_input = widgets.Text(\n",
        "    placeholder='Type your message here...',\n",
        "    description='You:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "# Send button\n",
        "send_button = widgets.Button(\n",
        "    description='Send',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='15%')\n",
        ")\n",
        "\n",
        "# Reset button\n",
        "reset_button = widgets.Button(\n",
        "    description='Reset Chat',\n",
        "    button_style='danger',\n",
        "    layout=widgets.Layout(width='15%')\n",
        ")\n",
        "\n",
        "# Temperature slider\n",
        "temperature_slider = widgets.FloatSlider(\n",
        "    value=0.8,\n",
        "    min=0.1,\n",
        "    max=1.5,\n",
        "    step=0.1,\n",
        "    description='Temperature:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        ")\n",
        "\n",
        "def update_chat_display():\n",
        "    \"\"\"Update the chat display with current conversation history.\"\"\"\n",
        "    history = chatbot.get_conversation_history()\n",
        "    html = \"\"\"\n",
        "    <style>\n",
        "        .chat-container { font-family: Arial, sans-serif; }\n",
        "        .user-message { background-color: #e6f7ff; padding: 10px; border-radius: 10px; margin: 5px 0; text-align: right; }\n",
        "        .assistant-message { background-color: #f1f1f1; padding: 10px; border-radius: 10px; margin: 5px 0; }\n",
        "    </style>\n",
        "    <div class=\"chat-container\">\n",
        "    \"\"\"\n",
        "    \n",
        "    for message in history:\n",
        "        if message['role'] == 'user':\n",
        "            html += f\"<div class='user-message'><strong>You:</strong> {message['text']}</div>\"\n",
        "        else:\n",
        "            html += f\"<div class='assistant-message'><strong>Laminet:</strong> {message['text']}</div>\"\n",
        "    \n",
        "    html += \"</div>\"\n",
        "    chat_history.value = html\n",
        "\n",
        "def on_send_clicked(b):\n",
        "    \"\"\"Handle send button click.\"\"\"\n",
        "    user_input = text_input.value\n",
        "    if not user_input.strip():\n",
        "        return\n",
        "    \n",
        "    # Clear input field\n",
        "    text_input.value = \"\"\n",
        "    \n",
        "    # Update temperature\n",
        "    chatbot.set_temperature(temperature_slider.value)\n",
        "    \n",
        "    # Process input and get response\n",
        "    response = chatbot.chat(user_input)\n",
        "    \n",
        "    # Update chat display\n",
        "    update_chat_display()\n",
        "\n",
        "def on_reset_clicked(b):\n",
        "    \"\"\"Handle reset button click.\"\"\"\n",
        "    chatbot.reset()\n",
        "    update_chat_display()\n",
        "    print(\"Chat history cleared.\")\n",
        "\n",
        "# Add event handlers\n",
        "send_button.on_click(on_send_clicked)\n",
        "reset_button.on_click(on_reset_clicked)\n",
        "\n",
        "# Handle Enter key in text input\n",
        "def on_enter(sender):\n",
        "    on_send_clicked(None)\n",
        "\n",
        "text_input.on_submit(on_enter)\n",
        "\n",
        "# Layout\n",
        "input_box = widgets.HBox([text_input, send_button])\n",
        "chat_interface = widgets.VBox([chat_history, input_box, temperature_slider, reset_button])\n",
        "\n",
        "# Display interface\n",
        "display(chat_interface)\n",
        "\n",
        "# Initial update\n",
        "update_chat_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates how to build a generative Laminet model that uses field evolution principles for text generation, rather than relying on transformer-based language models.\n",
        "\n",
        "Key components include:\n",
        "\n",
        "1. **Field-Based Generator**: Generates text by evolving semantic field points rather than using attention mechanisms\n",
        "2. **Semantic Field Evolution**: Uses physical-like forces to model semantic relationships\n",
        "3. **Dynamic Generation**: Creates new text that reflects semantic transitions in the field\n",
        "\n",
        "Unlike the original Laminet model which only retrieved existing texts, this model generates entirely new responses based on the semantic field evolution. This approach aligns with the Laminet philosophy of moving away from transformer architectures towards continuous field evolution models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}